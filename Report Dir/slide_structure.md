# Slide scripts for presentation
## introduction - 1
#### Slide 1:
## problems
## ro&&rq
## baseline model
## generative model
âš¡ Training Characteristics
Parameter Efficiency: Only the mapping network is trained (~1% of parameters)
Loss Calculation: Only text tokens contribute to loss; visual prefixes are masked
Objective: Causal language modeling, learning cross-modal alignment
Advantages: Reduces computational complexity, prevents overfitting on small datasets


ğŸ’¡ Summary of Evaluation Principles
Task Adaptability: Different evaluation metrics for different question types

Medical Specificity: Considers clinical validity and semantic accuracy

Benchmark Consistency: Follows Med-VQA domain standard practices

Comprehensiveness: Multi-dimensional assessment of model capabilities
## methods
## results


## comparison
## conclusion



# Generative Model Experimental Results Analysis
Page 1: Training Performance and Overall Results
ğŸ“‰ Training Loss Curve Characteristics
Rapid Initial Decline: Sharp drop from Epoch 0 to Epoch 1

Cause Analysis:

Both CLIP encoder and GPT-2 model remain frozen

Only requires learning simple visual-text alignment mapping

Model quickly converges to a reasonable solution

Stable Phase: Entering plateau around Epoch 5

Loss stabilizes around 0.3 with minimal fluctuation

Learning rate (1e-4) and AdamW optimizer appropriately set

ğŸ“Š Overall Performance Evaluation Results
Question Type	Accuracy	BLEU-1	BERTScore-F1
Closed-Ended Questions	63.03%	â€“	â€“
Open-Ended Questions	â€“	0.084	0.911
Overall	36.00%	â€“	â€“
ğŸ” Key Findings
Stable Closed Question Performance: 63% accuracy indicates reliable abnormality detection

Open Question Evaluation Divergence:

Extremely Low Surface Metrics: Exact Match 5.7%, BLEU-1 only 0.084

High Semantic Score: BERTScore-F1 reaches 0.911

Core Contradiction: Severe separation between surface form and semantic content

Page 2: Difference Analysis and Model Insights
âš™ï¸ Experimental Differences and Their Impact
1. Prefix Configuration Differences
Prefix Length: lx=10, lq/la=128 (fixed long prefixes)

Comparison: Previous work used shorter or dynamic prefixes

Impact: Long prefixes dilute visual information injection, particularly affecting open-ended answer generation

2. Language Model Limitations
Model Selection: GPT2-base (fewer parameters)

Comparison: Previous work used GPT2-XL or BioMedLM

Impact:

Limits precise word form generation ability

Insufficient lexical expression precision leads to low BLEU

Semantic content remains intact

3. Training Strategy Impact
Freezing Strategy: Language model completely frozen

Dataset Scale: Only VQA-RAD (small scale)

Optimizer: Lower learning rate, no warmup

Combined Impact: Constrains surface form accuracy while preserving semantic correctness

ğŸ’¡ Core Insights and Evaluation Reflections
ğŸ”„ Evaluation Metric Sensitivity Analysis
Metric Type	Sensitivity	Medical VQA Applicability
BLEU	Highly sensitive to word-level differences and short answer length	May underestimate model's clinical reasoning ability
BERTScore	Captures semantic similarity, considers synonyms	More comprehensively reflects clinical relevance
Accuracy	Directly effective for closed questions	Cannot assess open question quality
ğŸ“ˆ Performance Feature Summary
High BERTScore-F1: Model captures clinically relevant semantics even with different word forms

Low Surface Metrics: Caused by prefix length, model capacity, freezing strategy, dataset scale

Closed Question Robustness: Binary decision tasks not significantly affected



## æ€§èƒ½å·®è·ä¸è¡¨è¾¾è´¨é‡
ç¬¬1é¡µï¼šRQ1 - åŸºçº¿æ¨¡å‹ä¸ç”Ÿæˆå¼æ¨¡å‹çš„æ€§èƒ½å·®è·
ğŸ“Š æ€§èƒ½å¯¹æ¯”ç»“æœ
æ¨¡å‹ç±»å‹	æµ‹è¯•å‡†ç¡®ç‡	ç›¸å¯¹æå‡	å…³é”®ç‰¹å¾
åŸºçº¿æ¨¡å‹ (ResNet-LSTM)	çº¦33%	-	æ¥è¿‘äºŒå…ƒåˆ†ç±»éšæœºçŒœæµ‹
ç”Ÿæˆå¼VLM (CLIP+GPT-2)	63.03%	+30ä¸ªç™¾åˆ†ç‚¹	è¯Šæ–­æ­£ç¡®æ€§æ˜¾è‘—æå‡
ğŸ” æ€§èƒ½å·®è·åŸå› åˆ†æ
1. è¡¨å¾å­¦ä¹ å·®å¼‚
åŸºçº¿æ¨¡å‹é—®é¢˜:

ä¸¥é‡è¿‡æ‹Ÿåˆç°è±¡

è®­ç»ƒå‡†ç¡®ç‡é«˜ä½†æµ‹è¯•æ€§èƒ½å¤§å¹…ä¸‹é™

ä»å°æ•°æ®é›†ä»å¤´è®­ç»ƒï¼Œæ³›åŒ–èƒ½åŠ›æœ‰é™

ç”Ÿæˆå¼æ¨¡å‹ä¼˜åŠ¿:

ä½¿ç”¨å†»ç»“çš„å¤§è§„æ¨¡é¢„è®­ç»ƒéª¨å¹²ç½‘ç»œ

CLIPï¼ˆè§†è§‰ç¼–ç ï¼‰+ GPT-2ï¼ˆè¯­è¨€ç”Ÿæˆï¼‰

è§†è§‰-è¯­ä¹‰å¯¹é½æä¾›å¼ºå½’çº³åç½®

2. ä½èµ„æºæ¡ä»¶ä¸‹çš„æ³›åŒ–èƒ½åŠ›
æ•°æ®é›†é™åˆ¶: VQA-RADè§„æ¨¡è¾ƒå°

é¢„è®­ç»ƒä¼˜åŠ¿: å³ä½¿ä¸æ›´æ–°éª¨å¹²ç½‘ç»œå‚æ•°ï¼Œé¢„è®­ç»ƒçŸ¥è¯†ä»å¯è¿ç§»

å¯¹é½å­¦ä¹ : æ˜ å°„ç½‘ç»œå­¦ä¹ æœ‰æ•ˆçš„è·¨æ¨¡æ€å¯¹é½ï¼Œæå‡ä¸‹æ¸¸ä»»åŠ¡è¡¨ç°

ğŸ’¡ æ ¸å¿ƒç»“è®º
ç”Ÿæˆå¼æ–¹æ³•æ˜¾è‘—ä¼˜è¶Š: åœ¨å°é—­å¼åŒ»å­¦é—®ç­”ä»»åŠ¡ä¸Šè¡¨ç°æ›´ä½³

é¢„è®­ç»ƒæ˜¯å…³é”®: å¤§è§„æ¨¡é¢„è®­ç»ƒæ¨¡å‹åœ¨å°æ•°æ®é›†ä¸Šä»èƒ½ä¿æŒè‰¯å¥½æ³›åŒ–

æ¶æ„è®¾è®¡å½±å“: å†»ç»“éª¨å¹²ç½‘ç»œ+è½»é‡æ˜ å°„ç½‘ç»œçš„ç»„åˆç­–ç•¥æœ‰æ•ˆ

ç¬¬2é¡µï¼šRQ2 - è¡¨è¾¾è´¨é‡ä¸å¹»è§‰é£é™©åˆ†æ
ğŸ“ˆ è¯„ä¼°æŒ‡æ ‡çš„"æ‚–è®º"ç°è±¡
æŒ‡æ ‡è¡¨ç°å¯¹æ¯”
è¯„ä¼°ç»´åº¦	æŒ‡æ ‡è¡¨ç°	è§£é‡Š
è¯æ³•ä¸¥æ ¼æŒ‡æ ‡	è¡¨ç°å·®	ç²¾ç¡®åŒ¹é…å’ŒBLEUåˆ†æ•°æä½
è¯­ä¹‰ç›¸ä¼¼åº¦æŒ‡æ ‡	è¡¨ç°ä¼˜	BERTScoreé«˜è¾¾0.911
ğŸ§  é”™è¯¯æ¡ˆä¾‹åˆ†æ
å…¸å‹å¤±è´¥æ¡ˆä¾‹ï¼ˆè¡¨10ï¼‰
çœŸå®ç­”æ¡ˆ	æ¨¡å‹é¢„æµ‹	æŒ‡æ ‡ç»“æœ	ä¸´åºŠè§£é‡Š
the brain	brain	BLEU-4=0.065	ä¸´åºŠå«ä¹‰å®Œå…¨ç›¸åŒ
right side	right	ç²¾ç¡®åŒ¹é…=0	ç¼ºå¤±ä¿®é¥°è¯­ï¼Œç©ºé—´æ¦‚å¿µæ­£ç¡®
diffusion weighted MRI	MRI	ç²¾ç¡®åŒ¹é…=0	æ­£ç¡®è¯†åˆ«æ¨¡æ€ï¼Œç¼ºå¤±å…·ä½“å­ç±»å‹
âš ï¸ å¹»è§‰é£é™©åˆ†ç±»
1. è½¯å¹»è§‰
ç‰¹å¾: æ”¹è¿°æˆ–æ›¿æ¢ä¸´åºŠç›¸å…³æœ¯è¯­

ç¤ºä¾‹: "brain" vs "the brain"

é£é™©ç­‰çº§: è¾ƒä½ï¼Œä¸å½±å“ä¸´åºŠå†³ç­–

åŸå› : è¯­è¨€æ¨¡å‹çš„æµç•…ç”Ÿæˆç‰¹æ€§

2. ç¡¬å¹»è§‰
ç‰¹å¾: ç¼–é€ ä¸å­˜åœ¨ç–¾ç—…æˆ–å‘ç°

ç¤ºä¾‹: é¢„æµ‹ä¸å­˜åœ¨ç—…å˜

é£é™©ç­‰çº§: è¾ƒé«˜ï¼Œå¯èƒ½å¯¼è‡´è¯¯è¯Š

æœ¬ç ”ç©¶è§‚å¯Ÿ: è¾ƒå°‘å‡ºç°ï¼Œå¾—ç›Šäºå†»ç»“GPT-2çš„è¿è´¯æ€§

ğŸ”¬ å®‰å…¨æ€§åˆ†æ
è¯­è¨€æ¨¡å‹å†»ç»“çš„ä¼˜åŠ¿
è¾“å‡ºè¿è´¯æ€§: å‡å°‘æ— æ„ä¹‰è¾“å‡º

æœ¯è¯­ä¸€è‡´æ€§: ä¿æŒåŒ»å­¦æœ¯è¯­å‡†ç¡®æ€§

é£é™©æ§åˆ¶: é™ä½ç¡¬å¹»è§‰å‘ç”Ÿæ¦‚ç‡

ä¸´åºŠé€‚ç”¨æ€§è¯„ä¼°
è¯­ä¹‰æ­£ç¡®æ€§ä¼˜å…ˆ: å³ä½¿è¯æ³•ä¸å®Œå…¨åŒ¹é…ï¼Œä¸´åºŠå«ä¹‰æ­£ç¡®å³å¯æ¥å—

ä¿®é¥°è¯­æ•æ„Ÿæ€§: ç¼ºå¤±éå…³é”®ä¿®é¥°è¯­å¯¹è¯Šæ–­å½±å“æœ‰é™

å­ç±»å‹ç‰¹å¼‚æ€§: è¯†åˆ«ä¸»æ¨¡æ€æ¯”ç²¾ç¡®å­ç±»å‹æ›´é‡è¦